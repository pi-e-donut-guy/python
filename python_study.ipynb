{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "word = 'I love Python programming'\n",
    "print(word[-18:-12])\n",
    "num = 2\n",
    "yo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "foo = [1,2,3]\n",
    "bar = foo.copy()\n",
    "print(foo * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love Python programmingI love Python programming'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "# Map function applies a function to an iterable and returns a map object.\n",
    "\n",
    "number_list = [1,2,3,4,5]\n",
    "squared_list = list(map(lambda x : x**2,number_list))\n",
    "print(squared_list) #-> [1, 4, 9, 16, 25]\n",
    "# Map appiles the lambda function to each element in the input list\n",
    "# Map -> [f(1),f(2),f(3),f(4),f(5)]\n",
    "\n",
    "# Reduce function applies a funtion to an iterable and reduces it to a single cumulative value.\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "sum_of_squared_list = reduce(lambda x , y : x + y , squared_list)\n",
    "print(sum_of_squared_list) #-> 55\n",
    "# Reduce nests the lambda function\n",
    "# Reduce -> f(f(f(f(1,2) ,f(3)),f(4)),f(5))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140430245517968\n",
      "140430245573632\n"
     ]
    }
   ],
   "source": [
    "a = (1,2,3,4)\n",
    "print(id(a))\n",
    "b = [4,5]\n",
    "a = a[:3]\n",
    "print(id(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140430245505408 140430245505408\n",
      "Akshay\n"
     ]
    }
   ],
   "source": [
    "info = {\"Name\":\"Akhil\", \"Age\": 27,\"List\": [\"yo\",\"bitch\"]}\n",
    "dup = info\n",
    "print(id(info),id(dup))\n",
    "info[\"Name\"] = \"Akshay\"\n",
    "print(dup.get(\"Name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Akshay\n",
      "Age 27\n",
      "List ['yo', 'bitch']\n"
     ]
    }
   ],
   "source": [
    "for key, value in info.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['Age'] = info[\"Age\"] + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 4, 'Hello', 'Akhil'}\n"
     ]
    }
   ],
   "source": [
    "ls = [2,3,4,\"Hello\",\"Akhil\",\"Akhil\"]\n",
    "s = set(ls)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "d = {0: 'Fish', 1: 'Bird', 2: 'Mammal'}\n",
    "for i in d:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "d = {0, 1, 2}\n",
    "for x in d:\n",
    "    print(d.add(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yo', 'hows', 'it', 'going', 'My', 'name', 'is', 'steve', 'I', 'am', 'gay']\n"
     ]
    }
   ],
   "source": [
    "para = [\"Yo hows it going\", \"My name is steve\", \"I am gay\"]\n",
    "\n",
    "# for sentence in para:\n",
    "#     for word in sentence.split()\n",
    "\n",
    "word_list = [word for sentence in para for word in sentence.split()]\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'is', 'I', 'am']\n"
     ]
    }
   ],
   "source": [
    "vowel_list = ['a','e','i','o','u']\n",
    "\n",
    "# for sentence in para:\n",
    "#     for word in sentence.split():\n",
    "#         if word[0] in vowel_list:\n",
    "\n",
    "vowel_word_list = [word for sentence in para for word in sentence.split() if word[0].lower() in vowel_list]\n",
    "print(vowel_word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 4 5\n",
      "1 2 4 5\n"
     ]
    }
   ],
   "source": [
    "a = {1,2,4,5}\n",
    "print(*a)\n",
    "print(1,2,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One two\n"
     ]
    }
   ],
   "source": [
    "a = {\"One\":1,\"two\":2}\n",
    "print(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hai ('hello', 'yo', 3, [1, 2, 4])\n",
      "Hai hello yo 3 [1, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "def suml(*a):\n",
    "    print(\"Hai\",a)\n",
    "    print(\"Hai\",*a)\n",
    "\n",
    "suml(\"hello\",\"yo\",3,[1,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, False, True, False, True, False, True, False, True]\n",
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "num = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "l1 = list(map(lambda x : x%2 == 0,num))\n",
    "print(l1)\n",
    "# Filter needs True/False list and filters the input list\n",
    "l2 = list(filter(lambda x : x%2 == 0,num))\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "max = reduce(lambda x, y : x if x > y else y,num)\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Read the input as an integer\n",
    "n = int(input())\n",
    "print(n)\n",
    "\n",
    "# Import the reduce() function\n",
    "from functools import reduce\n",
    "\n",
    "# Write your code here\n",
    "if n == 0 : \n",
    "    fact = 1\n",
    "else:\n",
    "    fact = reduce(lambda x,y : x*y, list(range(1,n+1)))\n",
    "    \n",
    "print(fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# learn more \n",
    "# sets and set theory using set datastructure.\n",
    "# args and kwargs\n",
    "# map,reduce,filter\n",
    "# list and dictionary comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array(range(5))\n",
    "print(dir(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' 'True' 'True']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1,2,True,\"True\"])\n",
    "print(arr)\n",
    "print(type(arr))\n",
    "#arr = np.array([1,2,True])\n",
    "#print(arr *2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(range(10))\n",
    "#arr[(arr > 4) and (arr < 9)]\n",
    "arr[(arr > 4) & (arr < 9)]\n",
    "\n",
    "# Difference between 'and' and '&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3. , 4.4],\n",
       "       [6. , 6.6],\n",
       "       [9. , 8.8]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[1,2],[2,3],[3,4]])\n",
    "arr * np.array([3,2.2])\n",
    "# Element wise multiplication with '*'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 1.]\n",
      "   [1. 1.]]\n",
      "\n",
      "  [[1. 1.]\n",
      "   [1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1.]\n",
      "   [1. 1.]]\n",
      "\n",
      "  [[1. 1.]\n",
      "   [1. 1.]]]]\n",
      "(2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((2,2,2,2))\n",
    "print(ones)\n",
    "print(ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] \n",
      "\n",
      "\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2 5]\n",
      " [3 4 6]\n",
      " [3 4 5]] \n",
      "\n",
      "\n",
      "\n",
      "[[1 2 5 3 4 6 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([[1,2],[3,4]])\n",
    "print(arr,\"\\n\\n\")\n",
    "print(arr.reshape(-1,2)) # \"-1\" in reshape implies that it is unspecified\n",
    "arr = np.array([[1,2,5],[3,4,6],[3,4,5]])\n",
    "print(arr,\"\\n\\n\\n\")\n",
    "print(arr.reshape(-1)) # just a single '-1' will unravel the array\n",
    "print(arr.reshape(1,-1)) # The dimension of the array is specified by the number of elements you specify in the tuple. Here, the answer is 2-D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string : abcdefg\n",
      "string[-5:] : cdefg\n",
      "string[-1:-5] : \n",
      "string[-5:-1] : cdef\n",
      "string[-5:-7] : \n",
      "string[-1:-6:-1] : gfedc\n",
      "string[-6:-1:-1] : \n"
     ]
    }
   ],
   "source": [
    "string = \"abcdefg\"\n",
    "\n",
    "print(\"string :\",string)\n",
    "\n",
    "print(\"string[-5:] :\",string[-5:])\n",
    "\n",
    "print(\"string[-1:-5] :\",string[-1:-5])\n",
    "\n",
    "print(\"string[-5:-1] :\",string[-5:-1])\n",
    "\n",
    "print(\"string[-5:-7] :\",string[-5:-7])\n",
    "\n",
    "#In all the above cases the step size is by default '1'.\n",
    "\n",
    "#So the string will always be read left to right.\n",
    "\n",
    "#Therefore the second parameter in the index should be greater than the first one.\n",
    "\n",
    "#else will return nothing\n",
    "\n",
    " \n",
    "\n",
    "print(\"string[-1:-6:-1] :\",string[-1:-6:-1])\n",
    "\n",
    "print(\"string[-6:-1:-1] :\",string[-6:-1:-1])\n",
    "\n",
    "#In the above example the step size was changed to '-1'.Hence the string is read right to left.\n",
    "\n",
    "#Here the first parameter in the index should be greater than the second.\n",
    "\n",
    "#else will return nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into this\n",
    "# DataFrames\n",
    "# Aggregation and GroupBy\n",
    "# Split->Apply->Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'range'>\n",
      "['__bool__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'count', 'index', 'start', 'step', 'stop']\n"
     ]
    }
   ],
   "source": [
    "# Iterators and Generators\n",
    "\n",
    "x = range(10)\n",
    "print(type(x))\n",
    "print(dir(x))\n",
    "\n",
    "import sys \n",
    "\n",
    "print(sys.getsizeof(x))\n",
    "print(sys.getsizeof([x for x in range(10)]))\n",
    "\n",
    "# Map function is an iterator\n",
    "# for loop calls next() on the iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# flake8: noqa\n",
      "\n",
      "__docformat__ = \"restructuredtext\"\n",
      "\n",
      "# Let users know if they're missing any of our hard dependencies\n",
      "hard_dependencies = (\"numpy\", \"pytz\", \"dateutil\")\n",
      "missing_dependencies = []\n",
      "\n",
      "for dependency in hard_dependencies:\n",
      "    try:\n",
      "        __import__(dependency)\n",
      "    except ImportError as e:\n",
      "        missing_dependencies.append(f\"{dependency}: {e}\")\n",
      "\n",
      "if missing_dependencies:\n",
      "    raise ImportError(\n",
      "        \"Unable to import required dependencies:\\n\" + \"\\n\".join(missing_dependencies)\n",
      "    )\n",
      "del hard_dependencies, dependency, missing_dependencies\n",
      "\n",
      "# numpy compat\n",
      "from pandas.compat import (\n",
      "    np_version_under1p18 as _np_version_under1p18,\n",
      "    is_numpy_dev as _is_numpy_dev,\n",
      ")\n",
      "\n",
      "try:\n",
      "    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib\n",
      "except ImportError as e:  # pragma: no cover\n",
      "    # hack but overkill to use re\n",
      "    module = str(e).replace(\"cannot import name \", \"\")\n",
      "    raise ImportError(\n",
      "        f\"C extension: {module} not built. If you want to import \"\n",
      "        \"pandas from the source directory, you may need to run \"\n",
      "        \"'python setup.py build_ext --force' to build the C extensions first.\"\n",
      "    ) from e\n",
      "\n",
      "from pandas._config import (\n",
      "    get_option,\n",
      "    set_option,\n",
      "    reset_option,\n",
      "    describe_option,\n",
      "    option_context,\n",
      "    options,\n",
      ")\n",
      "\n",
      "# let init-time option registration happen\n",
      "import pandas.core.config_init\n",
      "\n",
      "from pandas.core.api import (\n",
      "    # dtype\n",
      "    Int8Dtype,\n",
      "    Int16Dtype,\n",
      "    Int32Dtype,\n",
      "    Int64Dtype,\n",
      "    UInt8Dtype,\n",
      "    UInt16Dtype,\n",
      "    UInt32Dtype,\n",
      "    UInt64Dtype,\n",
      "    Float32Dtype,\n",
      "    Float64Dtype,\n",
      "    CategoricalDtype,\n",
      "    PeriodDtype,\n",
      "    IntervalDtype,\n",
      "    DatetimeTZDtype,\n",
      "    StringDtype,\n",
      "    BooleanDtype,\n",
      "    # missing\n",
      "    NA,\n",
      "    isna,\n",
      "    isnull,\n",
      "    notna,\n",
      "    notnull,\n",
      "    # indexes\n",
      "    Index,\n",
      "    CategoricalIndex,\n",
      "    Int64Index,\n",
      "    UInt64Index,\n",
      "    RangeIndex,\n",
      "    Float64Index,\n",
      "    MultiIndex,\n",
      "    IntervalIndex,\n",
      "    TimedeltaIndex,\n",
      "    DatetimeIndex,\n",
      "    PeriodIndex,\n",
      "    IndexSlice,\n",
      "    # tseries\n",
      "    NaT,\n",
      "    Period,\n",
      "    period_range,\n",
      "    Timedelta,\n",
      "    timedelta_range,\n",
      "    Timestamp,\n",
      "    date_range,\n",
      "    bdate_range,\n",
      "    Interval,\n",
      "    interval_range,\n",
      "    DateOffset,\n",
      "    # conversion\n",
      "    to_numeric,\n",
      "    to_datetime,\n",
      "    to_timedelta,\n",
      "    # misc\n",
      "    Flags,\n",
      "    Grouper,\n",
      "    factorize,\n",
      "    unique,\n",
      "    value_counts,\n",
      "    NamedAgg,\n",
      "    array,\n",
      "    Categorical,\n",
      "    set_eng_float_format,\n",
      "    Series,\n",
      "    DataFrame,\n",
      ")\n",
      "\n",
      "from pandas.core.arrays.sparse import SparseDtype\n",
      "\n",
      "from pandas.tseries.api import infer_freq\n",
      "from pandas.tseries import offsets\n",
      "\n",
      "from pandas.core.computation.api import eval\n",
      "\n",
      "from pandas.core.reshape.api import (\n",
      "    concat,\n",
      "    lreshape,\n",
      "    melt,\n",
      "    wide_to_long,\n",
      "    merge,\n",
      "    merge_asof,\n",
      "    merge_ordered,\n",
      "    crosstab,\n",
      "    pivot,\n",
      "    pivot_table,\n",
      "    get_dummies,\n",
      "    cut,\n",
      "    qcut,\n",
      ")\n",
      "\n",
      "import pandas.api\n",
      "from pandas.util._print_versions import show_versions\n",
      "\n",
      "from pandas.io.api import (\n",
      "    # excel\n",
      "    ExcelFile,\n",
      "    ExcelWriter,\n",
      "    read_excel,\n",
      "    # parsers\n",
      "    read_csv,\n",
      "    read_fwf,\n",
      "    read_table,\n",
      "    # pickle\n",
      "    read_pickle,\n",
      "    to_pickle,\n",
      "    # pytables\n",
      "    HDFStore,\n",
      "    read_hdf,\n",
      "    # sql\n",
      "    read_sql,\n",
      "    read_sql_query,\n",
      "    read_sql_table,\n",
      "    # misc\n",
      "    read_clipboard,\n",
      "    read_parquet,\n",
      "    read_orc,\n",
      "    read_feather,\n",
      "    read_gbq,\n",
      "    read_html,\n",
      "    read_xml,\n",
      "    read_json,\n",
      "    read_stata,\n",
      "    read_sas,\n",
      "    read_spss,\n",
      ")\n",
      "\n",
      "from pandas.io.json import _json_normalize as json_normalize\n",
      "\n",
      "from pandas.util._tester import test\n",
      "import pandas.testing\n",
      "import pandas.arrays\n",
      "\n",
      "# use the closest tagged version if possible\n",
      "from pandas._version import get_versions\n",
      "\n",
      "v = get_versions()\n",
      "__version__ = v.get(\"closest-tag\", v[\"version\"])\n",
      "__git_version__ = v.get(\"full-revisionid\")\n",
      "del get_versions, v\n",
      "\n",
      "\n",
      "# GH 27101\n",
      "def __getattr__(name):\n",
      "    import warnings\n",
      "\n",
      "    if name == \"datetime\":\n",
      "        warnings.warn(\n",
      "            \"The pandas.datetime class is deprecated \"\n",
      "            \"and will be removed from pandas in a future version. \"\n",
      "            \"Import from datetime module instead.\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "\n",
      "        from datetime import datetime as dt\n",
      "\n",
      "        return dt\n",
      "\n",
      "    elif name == \"np\":\n",
      "\n",
      "        warnings.warn(\n",
      "            \"The pandas.np module is deprecated \"\n",
      "            \"and will be removed from pandas in a future version. \"\n",
      "            \"Import numpy directly instead\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "        import numpy as np\n",
      "\n",
      "        return np\n",
      "\n",
      "    elif name in {\"SparseSeries\", \"SparseDataFrame\"}:\n",
      "        warnings.warn(\n",
      "            f\"The {name} class is removed from pandas. Accessing it from \"\n",
      "            \"the top-level namespace will also be removed in the next version\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "\n",
      "        return type(name, (), {})\n",
      "\n",
      "    elif name == \"SparseArray\":\n",
      "\n",
      "        warnings.warn(\n",
      "            \"The pandas.SparseArray class is deprecated \"\n",
      "            \"and will be removed from pandas in a future version. \"\n",
      "            \"Use pandas.arrays.SparseArray instead.\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "        from pandas.core.arrays.sparse import SparseArray as _SparseArray\n",
      "\n",
      "        return _SparseArray\n",
      "\n",
      "    raise AttributeError(f\"module 'pandas' has no attribute '{name}'\")\n",
      "\n",
      "\n",
      "# module level doc-string\n",
      "__doc__ = \"\"\"\n",
      "pandas - a powerful data analysis and manipulation library for Python\n",
      "=====================================================================\n",
      "\n",
      "**pandas** is a Python package providing fast, flexible, and expressive data\n",
      "structures designed to make working with \"relational\" or \"labeled\" data both\n",
      "easy and intuitive. It aims to be the fundamental high-level building block for\n",
      "doing practical, **real world** data analysis in Python. Additionally, it has\n",
      "the broader goal of becoming **the most powerful and flexible open source data\n",
      "analysis / manipulation tool available in any language**. It is already well on\n",
      "its way toward this goal.\n",
      "\n",
      "Main Features\n",
      "-------------\n",
      "Here are just a few of the things that pandas does well:\n",
      "\n",
      "  - Easy handling of missing data in floating point as well as non-floating\n",
      "    point data.\n",
      "  - Size mutability: columns can be inserted and deleted from DataFrame and\n",
      "    higher dimensional objects\n",
      "  - Automatic and explicit data alignment: objects can be explicitly aligned\n",
      "    to a set of labels, or the user can simply ignore the labels and let\n",
      "    `Series`, `DataFrame`, etc. automatically align the data for you in\n",
      "    computations.\n",
      "  - Powerful, flexible group by functionality to perform split-apply-combine\n",
      "    operations on data sets, for both aggregating and transforming data.\n",
      "  - Make it easy to convert ragged, differently-indexed data in other Python\n",
      "    and NumPy data structures into DataFrame objects.\n",
      "  - Intelligent label-based slicing, fancy indexing, and subsetting of large\n",
      "    data sets.\n",
      "  - Intuitive merging and joining data sets.\n",
      "  - Flexible reshaping and pivoting of data sets.\n",
      "  - Hierarchical labeling of axes (possible to have multiple labels per tick).\n",
      "  - Robust IO tools for loading data from flat files (CSV and delimited),\n",
      "    Excel files, databases, and saving/loading data from the ultrafast HDF5\n",
      "    format.\n",
      "  - Time series-specific functionality: date range generation and frequency\n",
      "    conversion, moving window statistics, date shifting and lagging.\n",
      "\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import pandas as pd\n",
    "\n",
    "print(inspect.getsource(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "string = \"Python\"\n",
    "string2 = \"go\"\n",
    "print(type(string))\n",
    "print(dir(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythongo\n",
      "Pythongo\n"
     ]
    }
   ],
   "source": [
    "print(string.__add__(string2))\n",
    "print(string + string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies.isnull().any().value_counts()\n",
    "# movies is a dataframe\n",
    "# .all() vs .any()\n",
    "# How to check for nulls in dataframe.Check how many columns with nulls."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
